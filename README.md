# NAG-BERT
[Non-Autoregressive Text Generation with Pre-trained Language Models](https://arxiv.org/abs/2102.08220)

Authors: Yixuan Su, Deng Cai, Yan Wang, David Vandyke, Simon Baker, Piji Li, and Nigel Collier

## Introduction:
In this repository, we provide the related resources to our paper. We provide training and inference code for text summarization task.

## 1. Enviornment Installtion:
```yaml
pip install -r requirements.txt
```
To install pyrouge, please refer to this [link](https://sagor-sarker.medium.com/how-to-install-rouge-pyrouge-in-ubuntu-16-04-7f0ec1cda81b)

## 2. Download Gigawords Data [here](https://drive.google.com/file/d/1Jx9yfx45UJmFsO6y9lBlkGshPD3tF8Xy/view?usp=sharing):
```yaml
unzip data.zip and replace it with the empty ./data folder.
```

## 3. Training
```yaml
```
```yaml
chmod +x ./train.sh
./train.sh
```

